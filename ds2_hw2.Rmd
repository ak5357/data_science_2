---
title: "Data Science II Homework 2"
author: "Arghya Kannadaguli (ak5357)"
date: "2025-03-17"
output: html_document
---

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(ggplot2)
library(splines)
library(caret)
library(nlme)
library(mgcv)
library(earth)
# library(bayesQR)

set.seed(2025)
```


**In this exercise, we explore the use of nonlinear models to analyze the “College” dataset, which contains statistics from 565 U.S. colleges, as reported in a previous issue of U.S. News & World Report. The response variable is the out-of-state tuition (`Outstate`), and the predictors are: **

* `Apps`: Number of applications received
* `Accept`: Number of applications accepted
* `Enroll`: Number of new students enrolled
* `Top10perc`: Pct. new students from top 10% of H.S. class
* `Top25perc`: Pct. new students from top 25% of H.S. class
* `F.Undergrad`: Number of fulltime undergraduates
* `P.Undergrad`: Number of parttime undergraduates
* `Room.Board`: Room and board costs
* `Books`: Estimated book costs
* `Personal`: Estimated personal spending
* `PhD`: Pct. of faculty with Ph.D.’s
* `Terminal`: Pct. of faculty with terminal degree
* `S.F.Ratio`: Student/faculty ratio
* `perc.alumni`: Pct. alumni who donate
* `Expend`: Instructional expenditure per student
* `Grad.Rate`: Graduation rate

**Partition the dataset into two parts: training data (80%) and test data (20%).**

```{r message = FALSE}
college = read_csv("data/college.csv") |> 
  janitor::clean_names() |> 
  select(-college)

dat_split = rsample::initial_split(data = college, prop = 0.8)
train_data = rsample::training(dat_split)
test_data = rsample::testing(dat_split)
```

## **Part a.**

**Fit smoothing spline models to predict out-of-state tuition (Outstate) using the percentage of alumni who donate (perc.alumni) as the only predictor, across a range of degrees of freedom. Plot the fitted curve for each degree of freedom. Describe the patterns you observe as the degrees of freedom change. Choose an appropriate degree of freedom for the model and plot this optimal fit. Explain the criteria you used to select the degree of freedom.**

**_Plotting the fitted curve for each degree of freedom, across a range of values:_** The following code block defines a range of values to explore for degree of freedom, plots the training dataset, and then iteratively generates and plots spline fits for each degree of freedom value on the train dataset. For each fit, it also calculates the mean squared error, which will be used later to select the optimal fit.
```{r}
# Define a range of DFs
df_range = c(2, 3, 4, 5, 6, 8, 10, 12, 14, 16, 18, 20)

# Scatter plot
plot(train_data$perc_alumni, train_data$outstate, 
     xlim = c(0,80),
     pch = 19,
     col = alpha("black", 0.7), 
     cex = 0.7,
     xlab = "Percentage of Alumni Who Donate", 
     ylab = "Out-of-State Tuition", 
     main = "Smoothing Spline Fits with\nVarying Degrees of Freedom")

# Color range for plotted spline fits
myCol = rainbow(length(df_range))

# Empty list to save mse values of all spline fits
mse_values = numeric(length(df_range))

# Iteratively add fit lines
for(i in length(df_range):1){
  # Generate fit
  spline_fit = smooth.spline(train_data$perc_alumni, train_data$outstate, df = df_range[i])
  
  # Plot fit
  lines(spline_fit, col = myCol[i], lwd = 2)
  
  # Calculate MSE
  predictions = predict(spline_fit, test_data$perc_alumni)$y
  mse_values[i] = mean((test_data$outstate - predictions)^2)
  
  print(paste("Degrees of Freedom:", df_range[i], "| MSE:", round(mse_values[i], 2)))
}

legend("topright", legend = paste("DF =", df_range), col = rainbow(length(df_range)), lwd = 2, cex = 0.8)
```

**_Describe the Patterns:_** As the degrees of freedom increase, the line becomes more wavy. With low degrees of freedom, the curve is smooth and less flexible, but could potentially be underfitting the data. With higher degrees of freedom, the curve becomes very flexible, but could potentially be overfitting the data. The middle range of degrees of freedom are most likely to provide a good balance of flexibility.

**_Choose an appropriate degree of freedom and plot._** Let's select optimal fit based on calculated mean squared error (MSE). The MSE is a measure of how well the spline fits the data. The spline with the lowest test MSE has most potential to provide an accurate fit.

```{r}
df = df_range[which.min(mse_values)]
spline_mse = min(mse_values)
spline_rmse = sqrt(spline_mse)
paste("Degrees of Freedom:", df, "| MSE:", round(spline_mse, 2))

cat("Smoothing Spline Model Test Error\n",
    df, "Degrees of Freedom\n",
    "MSE:\t", spline_mse, "\n",
    "RMSE:\t", spline_rmse)
```

According to the MSE calculations, the optimal degree of freedom for the smoothing spline fit for this data is `r df`. Now let's plot this optimal fit.

```{r}
optimal_spline = smooth.spline(train_data$perc_alumni, train_data$outstate, df = df)

ggplot(data = test_data, aes(x = perc_alumni, y = outstate)) +
  geom_line(aes(y = predict(optimal_spline, test_data$perc_alumni)$y), color = "maroon", lwd = 0.8) +
  geom_point(col = "black", alpha = 0.5) +
  labs(
    x = "Percent Alumni who Donate",
    y = "Out-of-state Tuition",
    title = "Optimal Smoothing Spline Fit",
    subtitle = paste(df, "degrees of freedom")
  ) +
  theme_classic() +
  theme(plot.title = element_text(face="bold", hjust = 0.5, size=12),
        plot.subtitle = element_text(face="italic", hjust = 0.5, size=8))
```

## **Part b**

**Train a multivariate adaptive regression spline (MARS) model to predict the response variable. Report the regression function. Present the partial dependence plot of an arbitrary predictor in your model. Report the test error.**

**Generate MARS model:**
```{r}
# Define Predictors and Response
x = model.matrix(outstate ~ ., train_data)[, -1]
y = train_data$outstate

# Define tuning parameter grid
mars_grid = expand.grid(degree = 1:3, nprune = 2:15)

# CV setup
set.seed(2025)
ctrl = trainControl(method = "cv", number = 10)

# Train MARS model
set.seed(2025)
mars_fit = train(x, y,
                 method = "earth",
                 tuneGrid = mars_grid,
                 trControl = ctrl)

# Visualize Model Training
ggplot(mars_fit)

# Final Tuning Parameters
mars_fit$bestTune
```

**Report regression function:** The coefficients below show the regression coefficients from the final model.
```{r}
# Coefficients of Optimal Model
coef(mars_fit$finalModel)
```

**Present partial dependence plot of an arbitrary predictor in my model:**
```{r}
# PDP for individual feature
p1 = pdp::partial(mars_fit, pred.var = c("expend"), grid.resolution = 10) |> autoplot()

# PDP for interaction between two features
p2 = pdp::partial(mars_fit, pred.var = c("expend", "perc_alumni"),
                   grid.resolution = 10) |>
     pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE,
                   screen = list(z = 20, x = -60))

# Display plots
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

**Test error:** The test error for the MARS model (RMSE: 1852.672) is lower than that of the smoothing spline model (RMSE: 2908.062).
```{r}
# Define test x and y
test.x = model.matrix(outstate ~ ., test_data)[, -1]
test.y = test_data$outstate

# Generate predictions using MARS model
mars_predictions = predict(mars_fit, newdata = test.x)

# Calculate test error
mars_mse = mean((test.y - mars_predictions)^2)
mars_rmse = sqrt(mars_mse)

# Output message
cat("MARS Model Test Error\n",
    "MSE:\t", mars_mse, "\n",
    "RMSE:\t", mars_rmse, "\n",
    "\n",
    "Smoothing Spline Model Test Error\n",
    df, "Degrees of Freedom\n",
    "MSE:\t", spline_mse, "\n",
    "RMSE:\t", spline_rmse)
```

## **Part c**

**Construct a generalized additive model (GAM) to predict the response variable. For the nonlinear terms included in your model, generate plots to visualize these relationships and discuss your observations. Report the test error.**

**Generate GAM model:**
```{r}
# Generate GAM model
set.seed(2025)
gam_fit = train(x, y,
                method = "gam",
                trControl = ctrl)

# Final Tuning Parameters
gam_fit$bestTune

# Coefficients of Optimal Model
gam_fit$finalModel
```

**Generate plots for nonlinear terms:** Based on the GAM final model shown above, we can see that five of the predictors were modeled as linear, two as almost linear, and the rest as non-linear.

| Predictor | EDF | Modeled as... |
| --- | --- | --- |
| top10perc | 1.00 | Linear |
| top25perc | 1.00 | Linear |
| p_undergrad | 1.00 | Linear |
| enroll | 1.00 | Linear |
| apps | 1.00 | Linear |
| personal | 1.37 | Almost linear |
| room_board | 1.65 | Almost linear |
| perc_alumni | 2.12 | Non-linear |
| accept | 2.12 | Non-linear |
| books | 2.40 | Non-linear |
| grad_rate | 3.56 | Non-linear |
| s_f_ratio | 4.84 | Non-linear |
| expend | 5.35 | Non-linear |
| terminal | 5.96 | Non-linear |
| ph_d | 6.49 | Non-linear |
| f_undergrad | 6.52 | Non-linear |


Below I have visualized the nonlinear terms using a trellis plot setup, adding a smooth line using "loess" method. 
```{r}
train_data |> 
  select(perc_alumni, accept, books, grad_rate, s_f_ratio, expend, terminal, ph_d, f_undergrad, outstate) |> 
  pivot_longer(
    cols = -outstate,
    names_to = "predictor",
    values_to = "value") |> 
  mutate(
    edf = case_match(predictor,
      "perc_alumni" ~ 2.12,
      "accept" ~ 2.12,
      "books" ~ 2.40,
      "grad_rate" ~ 3.56,
      "s_f_ratio" ~ 4.84,
      "expend" ~ 5.35,
      "terminal" ~ 5.96,
      "ph_d" ~ 6.49,
      "f_undergrad" ~ 6.52),
    predictor = paste0(predictor, " (edf = ", edf, ")")) |> 
  ggplot(aes(x = value, y = outstate)) +
  geom_point(color = "darkgreen", alpha = 0.3) +
  geom_smooth(method = "loess", color = "black", linewidth = 0.5, se = TRUE) +
  facet_wrap(~ predictor, nrow = 3, scale = "free_x") +
  labs(title = "GAM Model Nonlinear Terms", y = "outstate") +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

**Discuss observations:** Predictors with higher EDFs (e.g. ph_d, terminal) show more clearly nonlinear relationships, with noticeable curves in the LOESS lines. In contrast, predictors with lower EDFs (e.g. perc_alumn, accept) show visual trends that are closer to linear. This visual evidence supports the model's estimation, since higher EDF corresponds to more flexibility. So it makes sense that the terms with higher EDFa have a more "wiggly" shape in their scatterplots.

**Report test error:** It appears that the GAM model has the lowest test error of the three models. GAM uses spline smoothers, rather than hinge functions like MARS, and it also includes all of the predictors, rather than just perc_alumni like the spline model. Perhaps the increased flexibility and 
```{r}
# Generate predictions using GAM model
gam_predictions = predict(gam_fit, newdata = test.x)

# Calculate test error
gam_mse = mean((test.y - gam_predictions)^2)
gam_rmse = sqrt(gam_mse)

# Output message
cat("GAM Model Test Error\n",
    "MSE:\t", gam_mse, "\n",
    "RMSE:\t", gam_rmse, "\n",
    "\n",
    "MARS Model Test Error\n",
    "MSE:\t", mars_mse, "\n",
    "RMSE:\t", mars_rmse, "\n",
    "\n",
    "Smoothing Spline Model Test Error\n",
    df, "Degrees of Freedom\n",
    "MSE:\t", spline_mse, "\n",
    "RMSE:\t", spline_rmse)
```

## **Part d**

**In this dataset, would you favor a MARS model over a linear model for predicting out-of-state tuition? If so, why? More broadly, in general applications, do you consider a MARS model to be superior to a linear model? Please share your reasoning.**

For this dataset, I would favor a MARS model over a linear model for predicting out-of-state tuition. For this comparison, we can consider the GAM model as a sensitivity analysis for exploring potential nonlinear relationships between predictors and the outcome. Based on the evidence of nonlinearity from the GAM, I would favor the MARS model, as it is better suited to capture nonlinear patterns.

Below, I have trained a linear model `glm_fit` to compare with the MARS model `mars_fit` from earlier. Comparing their validation errors, we can see that the MARS model's validation RMSE is lower. This is additional evidence that the MARS model provides a better fit for the dataset than a linear model.

In general applications, I would not always consider a MARS model to be superior to a linear model. While MARS is flexible and can model nonlinear relationships and interactions automatically, this also means that the resulting model may be more complex and more prone to overfitting than a linear model. The choice between MARS and a linear model should depend on the dataset and whether there is evidence for nonlinear relationships between the predictors and the outcome.

```{r}
# Generate Linear Model
set.seed(2025)
glm_fit = train(x, y,
                method = "glm",
                trControl = ctrl)

# GLM Validation Error
glm_cv_rmse = glm_fit$results$RMSE

# MARS Validation Error
mars_cv_rmse = mars_fit$results |> 
  filter(nprune == mars_fit$bestTune$nprune,
         degree == mars_fit$bestTune$degree) |> 
  pull(RMSE)

cat("MARS Model Validation Error\n",
    "RMSE:\t", glm_cv_rmse, "\n",
    "\n",
    "Linear Model Validation Error\n",
    "RMSE:\t", mars_cv_rmse)
```


